# products/forecast.py (Enhanced ARIMA Implementation)\nfrom prophet import Prophet\nimport pandas as pd\nimport logging\nfrom statsmodels.tsa.arima.model import ARIMA  # Import ARIMA\nfrom statsmodels.tools.sm_exceptions import ValueWarning, HessianInversionWarning, ConvergenceWarning\nimport warnings\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport numpy as np\n\nlogger = logging.getLogger(__name__)\n\n\nwarnings.simplefilter('ignore', ValueWarning)\nwarnings.simplefilter('ignore', HessianInversionWarning)\nwarnings.simplefilter('ignore', ConvergenceWarning)\n\n\ndef forecast_demand_prophet(product_sku, historical_data, horizon):\n    """Generates demand forecast using Prophet."""\n    try: # Added try-except block\n\n        # 1. Data Preparation\n        df = historical_data[['transaction_date', 'quantity']].rename(\n            columns={'transaction_date': 'ds', 'quantity': 'y'})\n\n        # Ensure 'ds' is datetime\n        df['ds'] = pd.to_datetime(df['ds'])\n\n        # Aggregate duplicate dates (SUM quantities for the same day) - CRUCIAL STEP\n        df = df.groupby('ds')['y'].sum().reset_index()\n\n        # Sort by date\n        df = df.sort_values('ds')\n\n        # 2. Train Prophet Model\n        model = Prophet()\n        model.fit(df)\n\n        # 3. Make Future DataFrame\n        future = model.make_future_dataframe(periods=horizon)\n\n        # 4. Forecast\n        forecast = model.predict(future)\n\n        # 5. Return Only Future Forecast Dates\n        forecast = forecast[forecast['ds'] > df['ds'].max()]\n\n        # 6. Ensure it is always returned as list\n        return forecast[['ds', 'yhat']].to_dict('records')\n\n    except Exception as e: # Catch any errors\n        logger.error(f"Prophet forecasting failed for SKU: {product_sku}. Error: {e}", exc_info=True)\n        return []  # Return an empty list as JSON is best if there is an error.\n\n\ndef forecast_demand_arima(product_sku, historical_data, horizon, arima_order=(5, 1, 0)):\n    """\n    Generates a demand forecast for a product using ARIMA (Corrected - Daily Aggregation).\n    """\n    logger.info(f"Generating ARIMA forecast for product SKU: {product_sku}, horizon: {horizon}, ARIMA order: {arima_order}")\n\n    df = historical_data[['transaction_date', 'quantity']].rename(columns={'transaction_date': 'ds', 'quantity': 'y'})\n\n    # --- Explicit Daily Aggregation (Fix for Duplicate Dates) ---\n    # Group by 'ds' (transaction_date) and sum 'y' (quantity) for each day\n    daily_df = df.groupby(pd.Grouper(key='ds', freq='D')).sum().reset_index() # Group by day and sum\n    ts = daily_df.set_index('ds')['y'].asfreq('D') # Now create daily TS\n    ts = ts.fillna(method='ffill')\n\n    logger.info(f"Time Series Data after Daily Aggregation - Shape: {ts.shape}, First 10 Dates: {ts.head(10).index.to_list()}") # Log shape and dates\n\n    try:\n        model = ARIMA(ts, order=arima_order)\n        model_fit = model.fit()\n\n        forecast_values = model_fit.forecast(steps=horizon)\n\n        forecast_dates = pd.date_range(start=ts.index[-1], periods=horizon, freq='D')\n        forecast_df = pd.DataFrame({'ds': forecast_dates, 'yhat': forecast_values.values})\n        return forecast_df[['ds', 'yhat']]\n\n    except Exception as e:\n        logger.error(f"ARIMA Forecasting error for SKU {product_sku}: {e}", exc_info=True)\n        raise e\ndef backtest_prophet_forecast(product_sku, historical_data, validation_horizon):\n    logger.info(f"Starting Prophet backtesting for SKU: {product_sku}, validation_horizon: {validation_horizon}")\n\n    # 1. Data Preparation\n    df = historical_data[['transaction_date', 'quantity']].rename(columns={'transaction_date': 'ds', 'quantity': 'y'})\n\n    # Ensure 'ds' is datetime\n    df['ds'] = pd.to_datetime(df['ds'])\n\n    # Aggregate duplicate dates (SUM quantities for the same day) - CRUCIAL STEP\n    df = df.groupby('ds')['y'].sum().reset_index()\n\n    # Sort by date\n    df = df.sort_values('ds')\n\n    # 2. Split Data into Training and Validation Sets\n    train_df = df[:-validation_horizon]\n    validation_df = df[-validation_horizon:]\n\n    print(f"train_df head:\n{train_df.head()}")  # Inspect the training data\n    print(f"validation_df head:\n{validation_df.head()}")  # Inspect the validation data\n    print(f"train_df tail:\n{train_df.tail()}")  # Inspect the tail of the training data\n    print(f"validation_df tail:\n{validation_df.tail()}")  # Inspect the tail of the validation data\n\n    if train_df.empty or validation_df.empty:\n        return {"error": "Insufficient data for backtesting. Need data for both training and validation periods."}\n\n    # 3. Train Prophet Model on Training Data ONLY\n    model = Prophet()\n    try:\n        model.fit(train_df)\n    except Exception as e:\n        logger.error(f"Prophet model.fit() failed: {e}", exc_info=True)\n        return {"error": f"Prophet model fitting failed: {str(e)}"}\n\n    # 4. Create DataFrame for VALIDATION PERIOD Dates for Forecasting (Corrected)\n    validation_future = pd.DataFrame({'ds': validation_df['ds']})\n    try:\n        validation_forecast = model.predict(validation_future)\n    except Exception as e:\n        logger.error(f"Prophet model.predict() failed: {e}", exc_info=True)\n        return {"error": f"Prophet model prediction failed: {str(e)}"}\n\n    print(f"validation_forecast head:\n{validation_forecast.head()}") #Inspect the validation forecast\n\n    # 5. Evaluate Forecast Accuracy\n    actual_values = validation_df['y'].values\n    forecasted_values = validation_forecast['yhat'].values\n\n    # Handle NaN values, which Prophet can sometimes produce.\n    actual_values = actual_values[np.isfinite(forecasted_values)]\n    forecasted_values = forecasted_values[np.isfinite(forecasted_values)]\n\n    if not actual_values.size or not forecasted_values.size:\n        metrics = {"mae": "NaN", "rmse": "NaN"}\n    else:\n        mae = mean_absolute_error(actual_values, forecasted_values)\n        rmse = np.sqrt(mean_squared_error(actual_values, forecasted_values))\n        metrics = {"mae": mae, "rmse": rmse}\n\n    logger.info(f"Prophet backtesting completed... Metrics: MAE={mae:.2f}, RMSE={rmse:.2f}")\n\n    # 6. Return Metrics and Validation Forecast\n    return {"metrics": metrics, "forecast": validation_forecast[['ds', 'yhat']].to_dict('records')}\ndef backtest_arima_forecast(product_sku, historical_data, validation_horizon, arima_order=(0, 0, 0)):\n    """\n    """\n    Performs ARIMA demand forecast backtesting on historical product data and evaluates forecasting accuracy.\n    \n    Args:\n        product_sku (str): Identifier for the product SKU.\n        historical_data (pandas.DataFrame): DataFrame containing historical demand data with columns 'ds' (date) and 'y' (quantity).\n        validation_horizon (int): Number of days to reserve for the validation/testing period.\n        arima_order (tuple, optional): The (p, d, q) order parameters for the ARIMA model. Defaults to (0, 0, 0).\n    \n    Returns:\n        dict: Contains keys:\n            - 'metrics' (dict): Evaluation metrics including mean absolute error ('mae') and root mean squared error ('rmse'), or error indicators if forecasting fails.\n            - 'forecast' (list): List of dictionaries with forecasted values for the validation period, each containing 'ds' (date) and 'yhat' (predicted quantity).\n            - 'arima_order_used' (tuple): The ARIMA order parameters used for model fitting.\n          If insufficient data or an error occurs during forecasting, returns a dictionary with an 'error' message and empty or NaN metrics and forecasts.\n    """\n    """\n    """\n    Performs backtesting for ARIMA demand forecast and evaluates accuracy.\n\n    Args:\n        product_sku (str): Product SKU.\n        historical_data (DataFrame): DataFrame with 'ds' and 'y' columns.\n        validation_horizon (int): Length of the validation period (number of days).\n        arima_order (tuple, optional): ARIMA model order (p, d, q). Defaults to (5, 1, 0).\n\n    Returns:\n        dict: Dictionary containing evaluation metrics (MAE, RMSE, etc.) and the forecast DataFrame for the validation period.\n    """\n    logger.info(f"Starting ARIMA backtesting for SKU: {product_sku}, validation_horizon: {validation_horizon}, ARIMA order: {arima_order}")\n\n    df = historical_data[['transaction_date', 'quantity']].rename(columns={'transaction_date': 'ds', 'quantity': 'y'})\n    # Group by 'ds' (transaction_date) and sum 'y' (quantity) for each day\n    daily_df = df.groupby(pd.Grouper(key='ds', freq='D')).sum().reset_index() # Group by day and sum\n    daily_df['ds'] = pd.to_datetime(daily_df['ds']) #Ensure that the ds is in datetime\n\n    ts = daily_df.set_index('ds')['y'] # Now create daily TS # REMOVE asfreq\n\n    # 1. Split Data into Training and Validation Sets\n    train_ts = ts[:-validation_horizon]  # Training data time series\n    validation_ts = ts[-validation_horizon:] # Validation data time series\n\n    if train_ts.empty or validation_ts.empty:\n        return {"error": "Insufficient data for backtesting. Need data for both training and validation periods."}\n\n    # 2. Train ARIMA Model on Training Data ONLY\n    model = ARIMA(train_ts, order=arima_order) #Use train_ts\n    try:\n        model_fit = model.fit()\n\n        # 3. Generate Forecast for Validation Period\n        forecast_values = model_fit.predict(start=validation_ts.index.min(), end=validation_ts.index.max()) # Forecast for validation dates\n\n        # Create a validation forecast dataframe with the same index\n        validation_forecast_df = pd.DataFrame({'ds': validation_ts.index, 'yhat': forecast_values}) # Create forecast DF\n\n        # 4. Evaluate Forecast Accuracy\n        actual_values = validation_ts.values #Use the ts_validation\n        forecasted_values = validation_forecast_df['yhat'].values\n\n        actual_values = actual_values[np.isfinite(forecasted_values)]\n        forecasted_values = forecasted_values[np.isfinite(forecasted_values)]\n\n        if not actual_values.size or not forecasted_values.size:\n            metrics = {"mae": "NaN", "rmse": "NaN"}\n        else:\n            mae = mean_absolute_error(actual_values, forecasted_values)\n            rmse = np.sqrt(mean_squared_error(actual_values, forecasted_values))\n            metrics = {"mae": mae, "rmse": rmse}\n\n        logger.info(f"ARIMA backtesting completed... Metrics: MAE={mae:.2f}, RMSE={rmse:.2f}, ARIMA order: {arima_order}") # Log ARIMA order\n\n        # 5. Return Metrics and Validation Forecast\n        return {"metrics": metrics, "forecast": validation_forecast_df[['ds', 'yhat']].to_dict('records'), "arima_order_used": arima_order} # Return arima_order_used\n\n    except Exception as e:\n        logger.error(f"ARIMA Forecasting error for SKU {product_sku}: {e}", exc_info=True)\n        return {"error": f"ARIMA forecasting failed: {str(e)}", "metrics": {"mae": "NaN", "rmse": "NaN"}, "forecast": []} #Return the error dictionary